{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "zdrsj _ modeling.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "XmJ8UxvBphg_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5RhLxIfuoeWB"
      },
      "outputs": [],
      "source": [
        "train_X, train_y = df.drop('price', axis=1), df['price']\n",
        "print(train_X.shape, train_y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 교차 검증 \n",
        "# 모델 선정 위해 (XGB, LGB) 모델의 성능 비교\n",
        "\n",
        "'''\n",
        " 시계열 데이터 - TimeSeriesSplit 기법을 사용\n",
        " 10개의 폴드로 구분\n",
        "  1) 과거의 데이터부터 끊어서 학습\n",
        "  2) 다음 폴드부터 이전 폴드까지 이용하여 반복적으로 교차검증\n",
        "  3) 미래의 데이터는 절대 학습하지 않으며 무조건 검증으로 사용됨\n",
        "'''\n",
        "\n",
        "def RMSE(y, y_pred):\n",
        "    rmse = mean_squared_error(y, y_pred) ** 0.5 \n",
        "    return rmse\n",
        "\n",
        "def rmse_cv(model):\n",
        "    # cv별로 학습하는 함수\n",
        "    tscv = TimeSeriesSplit(n_splits=10) # 10개의 폴드로 구분\n",
        "    rmse_list = []\n",
        "    model_name = model.__class__.__name__\n",
        "    for _, (train_index, test_index) in tqdm(enumerate(tscv.split(train_X), start=1), desc=f'{model_name} Cross Validations...', total=10):\n",
        "        X_train, X_test = train_X.iloc[train_index], train_X.iloc[test_index]\n",
        "        y_train, y_test = train_y.iloc[train_index], train_y.iloc[test_index]\n",
        "        clf = model.fit(X_train, y_train)\n",
        "        pred = clf.predict(X_test)\n",
        "        rmse = RMSE(y_test, pred) \n",
        "        rmse_list.append(rmse)\n",
        "    return model_name, rmse_list\n",
        "\n",
        "def print_rmse_score(model):\n",
        "    # cv별 프린팅, 평균 저장\n",
        "    model_name, score = rmse_cv(model)\n",
        "    for i, r in enumerate(score, start=1):\n",
        "        print(f'{i} FOLDS: {model_name} RMSLE: {r:.4f}')\n",
        "    print(f'\\n{model_name} mean RMSLE: {np.mean(score):.4f}')\n",
        "    print('='*40)\n",
        "    return model_name, np.mean(score)"
      ],
      "metadata": {
        "id": "oYxAkKR8qFOJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# XGB, LGB 모델 설정 \n",
        "\n",
        "model_xgb = xgb.XGBRegressor(n_estimators=500, max_depth=9, min_child_weight=5, gamma=0.1, n_jobs=-1)\n",
        "model_lgb = lgb.LGBMRegressor(n_estimators=500, max_depth=9, min_child_weight=5, n_jobs=-1)"
      ],
      "metadata": {
        "id": "OsA7oTuvqIy5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "models = []\n",
        "scores = []\n",
        "for model in [model_xgb, model_lgb]:\n",
        "    model_name, mean_score = print_rmse_score(model)\n",
        "    models.append(model_name)\n",
        "    scores.append(mean_score)"
      ],
      "metadata": {
        "id": "eufT7cTMqQwi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_df = pd.DataFrame({'Model': models, 'Score': scores}).reset_index(drop=True)\n",
        "result_df"
      ],
      "metadata": {
        "id": "CWVMv45UrBf6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 성능 시각화하여 확인\n",
        "\n",
        "f, ax = plt.subplots(figsize=(10, 6))\n",
        "plt.xticks(rotation='90')\n",
        "sns.barplot(x=result_df['Model'], y=result_df['Score'])\n",
        "plt.xlabel('Models', fontsize=15)\n",
        "plt.ylabel('Model Performance', fontsize=15)\n",
        "plt.ylim(0.22, 0.32)\n",
        "plt.title('RMSLE', fontsize=15)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3Y4t4NdxrFOb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train, valid split \n",
        "\n",
        "cut = int(len(train_df)*0.8) # traun, valid 80:20 으로 split\n",
        "train = train_df[:cut]\n",
        "valid = train_df[cut:]\n",
        "\n",
        "train_X = train.drop('price', axis=1)\n",
        "train_y = train['price']\n",
        "valid_X = valid.drop('price', axis=1)\n",
        "valid_y = valid['price']\n",
        "print(train_X.shape, train_y.shape, valid_X.shape, valid_y.shape)"
      ],
      "metadata": {
        "id": "ueAMQcSBsyKC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_X.head()"
      ],
      "metadata": {
        "id": "jcMfY-1stXp5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 하이퍼 파라미터 튜닝\n",
        "# 시간 이슈 때문에 TimeSeriesSplit은 적용하지 않음\n",
        "\n",
        "from optuna.samplers import TPESampler\n",
        "\n",
        "sampler = TPESampler(seed=10)\n",
        "\n",
        "def objective(trial):\n",
        "    dtrain = lgb.Dataset(train_X, label=train_y)\n",
        "    dtest = lgb.Dataset(valid_X, label=valid_y)\n",
        "\n",
        "    param = {\n",
        "        'objective': 'regression', # 회귀\n",
        "        'verbose': -1,\n",
        "        'metric': 'rmse', \n",
        "        'max_depth': trial.suggest_int('max_depth',3, 15),\n",
        "        'learning_rate': trial.suggest_loguniform(\"learning_rate\", 1e-8, 1e-2),\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 100, 3000),\n",
        "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
        "        'subsample': trial.suggest_loguniform('subsample', 0.4, 1),\n",
        "    }\n",
        "\n",
        "    model = lgb.LGBMRegressor(**param)\n",
        "    lgb_model = model.fit(train_X, train_y, eval_set=[(valid_X, valid_y)], verbose=0, early_stopping_rounds=25)\n",
        "    rmse = RMSE(valid_y, lgb_model.predict(valid_X))\n",
        "    return rmse\n",
        "       \n",
        "study_lgb = optuna.create_study(direction='minimize', sampler=sampler)\n",
        "study_lgb.optimize(objective, n_trials=100)"
      ],
      "metadata": {
        "id": "vjjGzY9vtmwt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trial = study_lgb.best_trial\n",
        "trial_params = trial.params\n",
        "print('Best Trial: score {},\\nparams {}'.format(trial.value, trial_params))"
      ],
      "metadata": {
        "id": "jodCKzuPuChB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터에 LightGBM model 적용\n",
        "\n",
        "final_lgb_model = lgb.LGBMRegressor(**trial_params)\n",
        "final_lgb_model.fit(train_X, train_y)\n",
        "final_lgb_pred = final_lgb_model.predict(test_df)"
      ],
      "metadata": {
        "id": "yyUzaPE0uODj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_lgb_pred"
      ],
      "metadata": {
        "id": "ORdGmEgduZ3z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.barh(train_X.columns, final_lgb_model.feature_importances_)"
      ],
      "metadata": {
        "id": "voJ4h_TJub45"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}