{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'xgboost'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/var/folders/1t/rxp10v3j0nnd0d43_pk_942h0000gn/T/ipykernel_39447/1997656632.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTimeSeriesSplit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlightgbm\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mlgb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
          ]
        }
      ],
      "source": [
        "# 필요한 라이브러리 import\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "from sklearn.linear_model import LinearRegression, ElasticNet, Lasso, Ridge\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.preprocessing import  LabelEncoder\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "import re\n",
        "import optuna\n",
        "from optuna.integration import XGBoostPruningCallback\n",
        "sns.set_theme(style=\"darkgrid\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XmJ8UxvBphg_"
      },
      "outputs": [],
      "source": [
        "# data 불러오기\n",
        "df = pd.read_csv('data/ml_data.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5RhLxIfuoeWB"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(11311, 14) (11311,)\n"
          ]
        }
      ],
      "source": [
        "train_X, train_y = df.drop('price', axis=1), df['price']\n",
        "print(train_X.shape, train_y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oYxAkKR8qFOJ"
      },
      "outputs": [],
      "source": [
        "# 교차 검증 \n",
        "# 모델 선정 위해 (XGB, LGB) 모델의 성능 비교\n",
        "\n",
        "'''\n",
        " 시계열 데이터 - TimeSeriesSplit 기법을 사용\n",
        " 10개의 폴드로 구분\n",
        "  1) 과거의 데이터부터 끊어서 학습\n",
        "  2) 다음 폴드부터 이전 폴드까지 이용하여 반복적으로 교차검증\n",
        "  3) 미래의 데이터는 절대 학습하지 않으며 무조건 검증으로 사용됨\n",
        "'''\n",
        "\n",
        "def RMSE(y, y_pred):\n",
        "    rmse = mean_squared_error(y, y_pred) ** 0.5 \n",
        "    return rmse\n",
        "\n",
        "def rmse_cv(model):\n",
        "    # cv별로 학습하는 함수\n",
        "    tscv = TimeSeriesSplit(n_splits=10) # 10개의 폴드로 구분\n",
        "    rmse_list = []\n",
        "    model_name = model.__class__.__name__\n",
        "    for _, (train_index, test_index) in tqdm(enumerate(tscv.split(train_X), start=1), desc=f'{model_name} Cross Validations...', total=10):\n",
        "        X_train, X_test = train_X.iloc[train_index], train_X.iloc[test_index]\n",
        "        y_train, y_test = train_y.iloc[train_index], train_y.iloc[test_index]\n",
        "        clf = model.fit(X_train, y_train)\n",
        "        pred = clf.predict(X_test)\n",
        "        rmse = RMSE(y_test, pred) \n",
        "        rmse_list.append(rmse)\n",
        "    return model_name, rmse_list\n",
        "\n",
        "def print_rmse_score(model):\n",
        "    # cv별 프린팅, 평균 저장\n",
        "    model_name, score = rmse_cv(model)\n",
        "    for i, r in enumerate(score, start=1):\n",
        "        print(f'{i} FOLDS: {model_name} RMSLE: {r:.4f}')\n",
        "    print(f'\\n{model_name} mean RMSLE: {np.mean(score):.4f}')\n",
        "    print('='*40)\n",
        "    return model_name, np.mean(score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OsA7oTuvqIy5"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'xgb' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/var/folders/1t/rxp10v3j0nnd0d43_pk_942h0000gn/T/ipykernel_39191/2009061759.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# XGB, LGB 모델 설정\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel_xgb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_child_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mmodel_lgb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLGBMRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_child_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'xgb' is not defined"
          ]
        }
      ],
      "source": [
        "# XGB, LGB 모델 설정 \n",
        "\n",
        "model_xgb = xgb.XGBRegressor(n_estimators=500, max_depth=9, min_child_weight=5, gamma=0.1, n_jobs=-1)\n",
        "model_lgb = lgb.LGBMRegressor(n_estimators=500, max_depth=9, min_child_weight=5, n_jobs=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eufT7cTMqQwi"
      },
      "outputs": [],
      "source": [
        "\n",
        "models = []\n",
        "scores = []\n",
        "for model in [model_xgb, model_lgb]:\n",
        "    model_name, mean_score = print_rmse_score(model)\n",
        "    models.append(model_name)\n",
        "    scores.append(mean_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CWVMv45UrBf6"
      },
      "outputs": [],
      "source": [
        "result_df = pd.DataFrame({'Model': models, 'Score': scores}).reset_index(drop=True)\n",
        "result_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Y4t4NdxrFOb"
      },
      "outputs": [],
      "source": [
        "# 모델 성능 시각화하여 확인\n",
        "\n",
        "f, ax = plt.subplots(figsize=(10, 6))\n",
        "plt.xticks(rotation='90')\n",
        "sns.barplot(x=result_df['Model'], y=result_df['Score'])\n",
        "plt.xlabel('Models', fontsize=15)\n",
        "plt.ylabel('Model Performance', fontsize=15)\n",
        "plt.ylim(0.22, 0.32)\n",
        "plt.title('RMSLE', fontsize=15)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ueAMQcSBsyKC"
      },
      "outputs": [],
      "source": [
        "# train, valid split \n",
        "\n",
        "cut = int(len(train_df)*0.8) # traun, valid 80:20 으로 split\n",
        "train = train_df[:cut]\n",
        "valid = train_df[cut:]\n",
        "\n",
        "train_X = train.drop('price', axis=1)\n",
        "train_y = train['price']\n",
        "valid_X = valid.drop('price', axis=1)\n",
        "valid_y = valid['price']\n",
        "print(train_X.shape, train_y.shape, valid_X.shape, valid_y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jcMfY-1stXp5"
      },
      "outputs": [],
      "source": [
        "train_X.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vjjGzY9vtmwt"
      },
      "outputs": [],
      "source": [
        "# 하이퍼 파라미터 튜닝\n",
        "# 시간 이슈 때문에 TimeSeriesSplit은 적용하지 않음\n",
        "\n",
        "from optuna.samplers import TPESampler\n",
        "\n",
        "sampler = TPESampler(seed=10)\n",
        "\n",
        "def objective(trial):\n",
        "    dtrain = lgb.Dataset(train_X, label=train_y)\n",
        "    dtest = lgb.Dataset(valid_X, label=valid_y)\n",
        "\n",
        "    param = {\n",
        "        'objective': 'regression', # 회귀\n",
        "        'verbose': -1,\n",
        "        'metric': 'rmse', \n",
        "        'max_depth': trial.suggest_int('max_depth',3, 15),\n",
        "        'learning_rate': trial.suggest_loguniform(\"learning_rate\", 1e-8, 1e-2),\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 100, 3000),\n",
        "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
        "        'subsample': trial.suggest_loguniform('subsample', 0.4, 1),\n",
        "    }\n",
        "\n",
        "    model = lgb.LGBMRegressor(**param)\n",
        "    lgb_model = model.fit(train_X, train_y, eval_set=[(valid_X, valid_y)], verbose=0, early_stopping_rounds=25)\n",
        "    rmse = RMSE(valid_y, lgb_model.predict(valid_X))\n",
        "    return rmse\n",
        "       \n",
        "study_lgb = optuna.create_study(direction='minimize', sampler=sampler)\n",
        "study_lgb.optimize(objective, n_trials=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jodCKzuPuChB"
      },
      "outputs": [],
      "source": [
        "trial = study_lgb.best_trial\n",
        "trial_params = trial.params\n",
        "print('Best Trial: score {},\\nparams {}'.format(trial.value, trial_params))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yyUzaPE0uODj"
      },
      "outputs": [],
      "source": [
        "# 데이터에 LightGBM model 적용\n",
        "\n",
        "final_lgb_model = lgb.LGBMRegressor(**trial_params)\n",
        "final_lgb_model.fit(train_X, train_y)\n",
        "final_lgb_pred = final_lgb_model.predict(test_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ORdGmEgduZ3z"
      },
      "outputs": [],
      "source": [
        "final_lgb_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "voJ4h_TJub45"
      },
      "outputs": [],
      "source": [
        "plt.barh(train_X.columns, final_lgb_model.feature_importances_)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "zdrsj _ modeling.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
